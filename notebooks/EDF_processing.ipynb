{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "196b6227",
   "metadata": {},
   "source": [
    "Sleep Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a10be978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyedflib\n",
      "  Downloading pyedflib-0.1.40.tar.gz (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /Users/mattikey/anaconda3/lib/python3.11/site-packages (from pyedflib) (1.24.3)\n",
      "Building wheels for collected packages: pyedflib\n",
      "  Building wheel for pyedflib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyedflib: filename=pyedflib-0.1.40-cp311-cp311-macosx_10_9_x86_64.whl size=2308891 sha256=43f130e83ee258449083b098a4af878e80064efeda5f152e574cf593a4e4c203\n",
      "  Stored in directory: /Users/mattikey/Library/Caches/pip/wheels/8d/df/d6/88ce619bde055ebffebae5380645802eca490817853b60b45b\n",
      "Successfully built pyedflib\n",
      "Installing collected packages: pyedflib\n",
      "Successfully installed pyedflib-0.1.40\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyedflib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf543012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import pyedflib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b45f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these functions to your notebook - these are the missing pieces!\n",
    "\n",
    "def process_hypnogram_enhanced(edf_path, subject_data=None):\n",
    "    \"\"\"\n",
    "    Enhanced hypnogram processing with subject data integration\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try MNE first\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "        annotations = raw.annotations\n",
    "        \n",
    "        # Extract metadata from filename\n",
    "        filename = Path(edf_path).name\n",
    "        file_metadata = parse_st_filename(filename)\n",
    "        \n",
    "        # Find matching subject data\n",
    "        subject_info = find_subject_info(file_metadata, subject_data)\n",
    "        \n",
    "        # Process sleep stages\n",
    "        hypnogram_data = []\n",
    "        \n",
    "        for i, (onset, duration, description) in enumerate(zip(\n",
    "            annotations.onset, annotations.duration, annotations.description)):\n",
    "            \n",
    "            stage = map_sleep_stage(description)\n",
    "            \n",
    "            hypnogram_data.append({\n",
    "                'epoch': i,\n",
    "                'onset_seconds': float(onset),\n",
    "                'duration_seconds': float(duration),\n",
    "                'onset_minutes': float(onset) / 60,\n",
    "                'onset_hours': float(onset) / 3600,\n",
    "                'stage': stage,\n",
    "                'stage_numeric': stage_to_numeric(stage),\n",
    "                'raw_description': description.strip()\n",
    "            })\n",
    "        \n",
    "        # Calculate comprehensive statistics\n",
    "        summary_stats = calculate_comprehensive_stats(hypnogram_data)\n",
    "        \n",
    "        # Recording metadata\n",
    "        recording_info = {\n",
    "            'duration_hours': (annotations.onset[-1] + annotations.duration[-1]) / 3600 if len(annotations) > 0 else 0,\n",
    "            'total_epochs': len(hypnogram_data),\n",
    "            'start_time': raw.info['meas_date'].isoformat() if raw.info['meas_date'] else None,\n",
    "            'sampling_rate': raw.info['sfreq'],\n",
    "            'epoch_length_seconds': 30  # Standard sleep scoring epoch\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'metadata': {\n",
    "                'filename': filename,\n",
    "                **file_metadata,\n",
    "                'subject_info': subject_info,\n",
    "                'study_type': 'Sleep Telemetry',\n",
    "                'recording_info': recording_info\n",
    "            },\n",
    "            'hypnogram': hypnogram_data,\n",
    "            'summary_stats': summary_stats\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {edf_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def parse_st_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse ST filename: ST7011JP-Hypnogram.edf\n",
    "    ST = Study Type\n",
    "    70 = Subject ID  \n",
    "    1 = Night\n",
    "    1 = Condition (0=placebo, 1=temazepam typically)\n",
    "    J = Additional identifier\n",
    "    P = Additional identifier\n",
    "    \"\"\"\n",
    "    base = filename.replace('-Hypnogram.edf', '').replace('-PSG.edf', '')\n",
    "    \n",
    "    if base.startswith('ST7'):\n",
    "        # Extract components\n",
    "        subject_id = base[3:5] if len(base) >= 5 else None\n",
    "        night_id = base[5:6] if len(base) >= 6 else None\n",
    "        condition_code = base[6:7] if len(base) >= 7 else None\n",
    "        \n",
    "        # Map condition code\n",
    "        condition_map = {'0': 'placebo', '1': 'temazepam', 'P': 'placebo', 'J': 'temazepam'}\n",
    "        condition = condition_map.get(condition_code, condition_code)\n",
    "        \n",
    "        return {\n",
    "            'subject_id': subject_id,\n",
    "            'night_id': night_id,\n",
    "            'condition': condition,\n",
    "            'condition_code': condition_code\n",
    "        }\n",
    "    \n",
    "    return {'subject_id': None, 'night_id': None, 'condition': None}\n",
    "\n",
    "def find_subject_info(file_metadata, subject_data):\n",
    "    \"\"\"\n",
    "    Find matching subject information from demographics data\n",
    "    \"\"\"\n",
    "    if not subject_data or not file_metadata.get('subject_id'):\n",
    "        return {'age': None, 'gender': None}\n",
    "    \n",
    "    subject_id = file_metadata['subject_id']\n",
    "    night_id = file_metadata['night_id']\n",
    "    condition = file_metadata['condition']\n",
    "    \n",
    "    # Look for matching record\n",
    "    for record in subject_data:\n",
    "        record_subj = str(record.get('subject', '')).zfill(2)\n",
    "        record_night = str(record.get('night', ''))\n",
    "        record_condition = str(record.get('condition', '')).lower()\n",
    "        \n",
    "        if (record_subj == subject_id and \n",
    "            record_night == night_id and\n",
    "            condition and record_condition in condition.lower()):\n",
    "            \n",
    "            return {\n",
    "                'age': record.get('age'),\n",
    "                'gender': record.get('gender'),\n",
    "                'condition_verified': record.get('condition')\n",
    "            }\n",
    "    \n",
    "    # If no exact match, try just subject ID\n",
    "    for record in subject_data:\n",
    "        record_subj = str(record.get('subject', '')).zfill(2)\n",
    "        if record_subj == subject_id:\n",
    "            return {\n",
    "                'age': record.get('age'),\n",
    "                'gender': record.get('gender'),\n",
    "                'condition_verified': None\n",
    "            }\n",
    "    \n",
    "    return {'age': None, 'gender': None}\n",
    "\n",
    "def map_sleep_stage(description):\n",
    "    \"\"\"Enhanced sleep stage mapping\"\"\"\n",
    "    desc = description.lower().strip()\n",
    "    \n",
    "    # Comprehensive mapping\n",
    "    if 'sleep stage w' in desc or desc == 'w':\n",
    "        return 'Wake'\n",
    "    elif 'sleep stage r' in desc or desc == 'r':\n",
    "        return 'REM'\n",
    "    elif 'sleep stage 1' in desc or desc == '1':\n",
    "        return 'N1'\n",
    "    elif 'sleep stage 2' in desc or desc == '2':\n",
    "        return 'N2'\n",
    "    elif 'sleep stage 3' in desc or desc == '3':\n",
    "        return 'N3'\n",
    "    elif 'sleep stage 4' in desc or desc == '4':\n",
    "        return 'N4'\n",
    "    elif 'movement' in desc or desc == 'm':\n",
    "        return 'Movement'\n",
    "    elif '?' in desc:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return description  # Keep original if no mapping found\n",
    "\n",
    "def stage_to_numeric(stage):\n",
    "    \"\"\"Convert stage to numeric for analysis\"\"\"\n",
    "    mapping = {\n",
    "        'Wake': 0, 'N1': 1, 'N2': 2, 'N3': 3, 'N4': 4, \n",
    "        'REM': 5, 'Movement': 6, 'Unknown': -1\n",
    "    }\n",
    "    return mapping.get(stage, -1)\n",
    "\n",
    "def calculate_comprehensive_stats(hypnogram_data):\n",
    "    \"\"\"Calculate comprehensive sleep statistics\"\"\"\n",
    "    if not hypnogram_data:\n",
    "        return {\n",
    "            'sleep_efficiency': 0.0,\n",
    "            'rem_percentage': 0.0,\n",
    "            'deep_sleep_percentage': 0.0,\n",
    "            'light_sleep_percentage': 0.0,\n",
    "            'wake_percentage': 100.0,\n",
    "            'stage_percentages': {},\n",
    "            'sleep_onset_minutes': None,\n",
    "            'rem_onset_minutes': None,\n",
    "            'total_sleep_time_hours': 0.0,\n",
    "            'wake_after_sleep_onset_minutes': 0.0\n",
    "        }\n",
    "    \n",
    "    # Calculate durations\n",
    "    total_duration = sum(epoch['duration_seconds'] for epoch in hypnogram_data)\n",
    "    stage_durations = {}\n",
    "    \n",
    "    for epoch in hypnogram_data:\n",
    "        stage = epoch['stage']\n",
    "        duration = epoch['duration_seconds']\n",
    "        stage_durations[stage] = stage_durations.get(stage, 0) + duration\n",
    "    \n",
    "    # Stage percentages\n",
    "    stage_percentages = {\n",
    "        stage: (duration / total_duration) * 100 \n",
    "        for stage, duration in stage_durations.items()\n",
    "    }\n",
    "    \n",
    "    # Key metrics\n",
    "    wake_time = stage_durations.get('Wake', 0)\n",
    "    rem_time = stage_durations.get('REM', 0)\n",
    "    n1_time = stage_durations.get('N1', 0)\n",
    "    n2_time = stage_durations.get('N2', 0)\n",
    "    n3_time = stage_durations.get('N3', 0)\n",
    "    n4_time = stage_durations.get('N4', 0)\n",
    "    \n",
    "    total_sleep_time = total_duration - wake_time\n",
    "    \n",
    "    # Find sleep onset (first non-wake stage)\n",
    "    sleep_onset_minutes = None\n",
    "    rem_onset_minutes = None\n",
    "    \n",
    "    for epoch in hypnogram_data:\n",
    "        if epoch['stage'] != 'Wake' and sleep_onset_minutes is None:\n",
    "            sleep_onset_minutes = epoch['onset_minutes']\n",
    "        if epoch['stage'] == 'REM' and rem_onset_minutes is None:\n",
    "            rem_onset_minutes = epoch['onset_minutes']\n",
    "    \n",
    "    return {\n",
    "        'sleep_efficiency': round((total_sleep_time / total_duration) * 100, 2) if total_duration > 0 else 0,\n",
    "        'rem_percentage': round((rem_time / total_duration) * 100, 2),\n",
    "        'deep_sleep_percentage': round(((n3_time + n4_time) / total_duration) * 100, 2),\n",
    "        'light_sleep_percentage': round(((n1_time + n2_time) / total_duration) * 100, 2),\n",
    "        'wake_percentage': round((wake_time / total_duration) * 100, 2),\n",
    "        'stage_percentages': {k: round(v, 2) for k, v in stage_percentages.items()},\n",
    "        'sleep_onset_minutes': round(sleep_onset_minutes, 1) if sleep_onset_minutes else None,\n",
    "        'rem_onset_minutes': round(rem_onset_minutes, 1) if rem_onset_minutes else None,\n",
    "        'total_sleep_time_hours': round(total_sleep_time / 3600, 2),\n",
    "        'wake_after_sleep_onset_minutes': round((wake_time - (sleep_onset_minutes * 60 if sleep_onset_minutes else 0)) / 60, 1) if sleep_onset_minutes else 0\n",
    "    }\n",
    "\n",
    "# Fix your ST_SUBJECTS_DATA - it needs proper formatting\n",
    "ST_SUBJECTS_DATA = \"\"\"\n",
    "Subject age sex Placebo_night Temazepam_night Nr Age M1F2 night_nr lights_off night_nr lights_off\n",
    "1 60 1 1 23:01 2 23:48\n",
    "2 35 2 2 23:27 1 0:00\n",
    "4 18 2 1 23:53 2 22:37\n",
    "5 32 2 2 23:23 1 23:34\n",
    "6 35 2 1 23:28 2 23:26\n",
    "7 51 2 1 0:02 2 23:24\n",
    "8 66 2 2 23:20 1 23:53\n",
    "9 47 1 2 0:30 1 23:42\n",
    "10 20 2 1 23:21 2 23:28\n",
    "11 21 2 2 23:52 1 23:38\n",
    "12 21 1 1 23:46 2 23:56\n",
    "13 22 1 2 0:31 1 0:38\n",
    "14 20 1 1 0:40 2 0:53\n",
    "15 66 2 1 23:42 2 23:33\n",
    "16 79 2 2 23:21 1 23:18\n",
    "17 48 2 1 23:40 2 23:48\n",
    "18 53 2 2 23:38 1 23:24\n",
    "19 28 2 2 23:22 1 23:44\n",
    "20 24 1 1 23:47 2 0:01\n",
    "21 34 2 2 23:44 1 23:10\n",
    "22 56 1 1 23:22 2 23:44\n",
    "24 48 2 1 23:27 2 23:36\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1685d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN PROCESSING PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def process_st_subjects_from_text(text_data):\n",
    "    \"\"\"\n",
    "    Process ST subjects data from the provided text format\n",
    "    \"\"\"\n",
    "    lines = text_data.strip().split('\\n')\n",
    "    \n",
    "    subjects = []\n",
    "    \n",
    "    # Skip header line and process each subject\n",
    "    for line in lines[1:]:  # Skip the header\n",
    "        if not line.strip():\n",
    "            continue\n",
    "            \n",
    "        parts = line.split()\n",
    "        if len(parts) >= 8:\n",
    "            subject_num = int(parts[0])\n",
    "            age = int(parts[1])\n",
    "            sex_code = int(parts[2])  # 1=Male, 2=Female\n",
    "            gender = 'M' if sex_code == 1 else 'F'\n",
    "            \n",
    "            placebo_night = int(parts[3])\n",
    "            placebo_time = parts[4]\n",
    "            temazepam_night = int(parts[5]) \n",
    "            temazepam_time = parts[6]\n",
    "            \n",
    "            # Create records for both nights\n",
    "            subjects.append({\n",
    "                'subject': f\"{subject_num:02d}\",\n",
    "                'age': age,\n",
    "                'gender': gender,\n",
    "                'night': placebo_night,\n",
    "                'condition': 'placebo',\n",
    "                'lights_off_time': placebo_time,\n",
    "                'study': 'ST'\n",
    "            })\n",
    "            \n",
    "            subjects.append({\n",
    "                'subject': f\"{subject_num:02d}\",\n",
    "                'age': age,\n",
    "                'gender': gender,\n",
    "                'night': temazepam_night,\n",
    "                'condition': 'temazepam',\n",
    "                'lights_off_time': temazepam_time,\n",
    "                'study': 'ST'\n",
    "            })\n",
    "    \n",
    "    print(f\"Processed {len(subjects)} subject records from {len(lines)-1} subjects\")\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "360fd736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_summary(processed_data, subject_data):\n",
    "    \"\"\"\n",
    "    Create comprehensive dataset summary for your project\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        'total_subjects': len(set(record['metadata']['subject_info'].get('age') for record in processed_data if record['metadata']['subject_info'].get('age'))),\n",
    "        'total_recordings': len(processed_data),\n",
    "        'conditions': {},\n",
    "        'age_distribution': [],\n",
    "        'gender_distribution': {},\n",
    "        'sleep_stats_by_condition': {},\n",
    "        'sleep_stats_by_age_group': {},\n",
    "        'sleep_stats_by_gender': {}\n",
    "    }\n",
    "    \n",
    "    # Group by conditions\n",
    "    condition_groups = {}\n",
    "    age_groups = {'18-30': [], '31-50': [], '51-70': [], '70+': []}\n",
    "    gender_groups = {'M': [], 'F': []}\n",
    "    \n",
    "    for record in processed_data:\n",
    "        if not record:\n",
    "            continue\n",
    "            \n",
    "        condition = record['metadata'].get('condition', 'unknown')\n",
    "        age = record['metadata']['subject_info'].get('age')\n",
    "        gender = record['metadata']['subject_info'].get('gender')\n",
    "        stats = record['summary_stats']\n",
    "        \n",
    "        # Condition grouping\n",
    "        if condition not in condition_groups:\n",
    "            condition_groups[condition] = []\n",
    "        condition_groups[condition].append(stats)\n",
    "        \n",
    "        # Age grouping\n",
    "        if age:\n",
    "            if age <= 30:\n",
    "                age_groups['18-30'].append(stats)\n",
    "            elif age <= 50:\n",
    "                age_groups['31-50'].append(stats)\n",
    "            elif age <= 70:\n",
    "                age_groups['51-70'].append(stats)\n",
    "            else:\n",
    "                age_groups['70+'].append(stats)\n",
    "        \n",
    "        # Gender grouping\n",
    "        if gender in gender_groups:\n",
    "            gender_groups[gender].append(stats)\n",
    "    \n",
    "    # Calculate averages for each group\n",
    "    summary['conditions'] = {k: len(v) for k, v in condition_groups.items()}\n",
    "    summary['sleep_stats_by_condition'] = {\n",
    "        condition: calculate_group_averages(stats_list)\n",
    "        for condition, stats_list in condition_groups.items()\n",
    "    }\n",
    "    \n",
    "    summary['sleep_stats_by_age_group'] = {\n",
    "        age_group: calculate_group_averages(stats_list)\n",
    "        for age_group, stats_list in age_groups.items() if stats_list\n",
    "    }\n",
    "    \n",
    "    summary['sleep_stats_by_gender'] = {\n",
    "        gender: calculate_group_averages(stats_list)\n",
    "        for gender, stats_list in gender_groups.items() if stats_list\n",
    "    }\n",
    "    \n",
    "    # Age and gender distributions\n",
    "    ages = [record['metadata']['subject_info'].get('age') for record in processed_data \n",
    "            if record and record['metadata']['subject_info'].get('age')]\n",
    "    genders = [record['metadata']['subject_info'].get('gender') for record in processed_data \n",
    "               if record and record['metadata']['subject_info'].get('gender')]\n",
    "    \n",
    "    summary['age_distribution'] = ages\n",
    "    summary['gender_distribution'] = {gender: genders.count(gender) for gender in set(genders)}\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5c990c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_group_averages(stats_list):\n",
    "    \"\"\"Calculate average statistics for a group\"\"\"\n",
    "    if not stats_list:\n",
    "        return {}\n",
    "    \n",
    "    avg_stats = {}\n",
    "    \n",
    "    # Calculate averages for numeric fields\n",
    "    numeric_fields = ['sleep_efficiency', 'rem_percentage', 'deep_sleep_percentage', \n",
    "                     'light_sleep_percentage', 'total_sleep_time_hours']\n",
    "    \n",
    "    for field in numeric_fields:\n",
    "        values = [stats.get(field, 0) for stats in stats_list if stats.get(field) is not None]\n",
    "        avg_stats[field] = round(sum(values) / len(values), 2) if values else 0\n",
    "    \n",
    "    # Calculate average stage percentages\n",
    "    all_stages = set()\n",
    "    for stats in stats_list:\n",
    "        if 'stage_percentages' in stats:\n",
    "            all_stages.update(stats['stage_percentages'].keys())\n",
    "    \n",
    "    avg_stage_percentages = {}\n",
    "    for stage in all_stages:\n",
    "        values = [stats['stage_percentages'].get(stage, 0) \n",
    "                 for stats in stats_list if 'stage_percentages' in stats]\n",
    "        avg_stage_percentages[stage] = round(sum(values) / len(values), 2) if values else 0\n",
    "    \n",
    "    avg_stats['stage_percentages'] = avg_stage_percentages\n",
    "    \n",
    "    return avg_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07474930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_processing(edf_data_dir, output_dir, st_subjects_text):\n",
    "    \"\"\"\n",
    "    Run the complete processing pipeline\n",
    "    \"\"\"\n",
    "    print(\"=== Starting Complete Sleep Data Processing ===\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Process subject demographics\n",
    "    print(\"\\n1. Processing subject demographics...\")\n",
    "    subject_data = process_st_subjects_from_text(st_subjects_text)\n",
    "    \n",
    "    # Save subject data\n",
    "    with open(output_path / \"st_subjects_processed.json\", 'w') as f:\n",
    "        json.dump(subject_data, f, indent=2)\n",
    "    \n",
    "    # Process hypnogram files\n",
    "    print(\"\\n2. Processing hypnogram files...\")\n",
    "    data_path = Path(edf_data_dir)\n",
    "    hypnogram_files = list(data_path.glob(\"*Hypnogram.edf\"))\n",
    "    \n",
    "    print(f\"Found {len(hypnogram_files)} hypnogram files\")\n",
    "    \n",
    "    processed_data = []\n",
    "    failed_files = []\n",
    "    \n",
    "    for file_path in hypnogram_files:\n",
    "        print(f\"Processing {file_path.name}...\")\n",
    "        \n",
    "        result = process_hypnogram_enhanced(file_path, subject_data)\n",
    "        \n",
    "        if result:\n",
    "            processed_data.append(result)\n",
    "            \n",
    "            # Save individual file\n",
    "            output_file = output_path / f\"{file_path.stem}.json\"\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(result, f, indent=2)\n",
    "        else:\n",
    "            failed_files.append(file_path.name)\n",
    "    \n",
    "    print(f\"\\n3. Processing complete!\")\n",
    "    print(f\"   Successfully processed: {len(processed_data)} files\")\n",
    "    print(f\"   Failed to process: {len(failed_files)} files\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(f\"   Failed files: {failed_files}\")\n",
    "    \n",
    "    # Create dataset summary\n",
    "    print(\"\\n4. Creating dataset summary...\")\n",
    "    dataset_summary = create_dataset_summary(processed_data, subject_data)\n",
    "    \n",
    "    # Save all results\n",
    "    with open(output_path / \"combined_sleep_data.json\", 'w') as f:\n",
    "        json.dump(processed_data, f, indent=2)\n",
    "    \n",
    "    with open(output_path / \"dataset_summary.json\", 'w') as f:\n",
    "        json.dump(dataset_summary, f, indent=2)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\n=== PROCESSING SUMMARY ===\")\n",
    "    print(f\"Total recordings processed: {len(processed_data)}\")\n",
    "    print(f\"Subjects with demographics: {len(subject_data)}\")\n",
    "    print(f\"Conditions found: {list(dataset_summary['conditions'].keys())}\")\n",
    "    print(f\"Age range: {min(dataset_summary['age_distribution'])}-{max(dataset_summary['age_distribution'])} years\")\n",
    "    print(f\"Gender distribution: {dataset_summary['gender_distribution']}\")\n",
    "    \n",
    "    return processed_data, dataset_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcb78c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting Complete Sleep Data Processing ===\n",
      "\n",
      "1. Processing subject demographics...\n",
      "Processed 0 subject records from 0 subjects\n",
      "\n",
      "2. Processing hypnogram files...\n",
      "Found 40 hypnogram files\n",
      "Processing ST7152JA-Hypnogram.edf...\n",
      "Processing ST7071JA-Hypnogram.edf...\n",
      "Processing ST7081JW-Hypnogram.edf...\n",
      "Processing ST7042JO-Hypnogram.edf...\n",
      "Processing ST7052JA-Hypnogram.edf...\n",
      "Processing ST7221JA-Hypnogram.edf...\n",
      "Processing ST7171JA-Hypnogram.edf...\n",
      "Processing ST7112JE-Hypnogram.edf...\n",
      "Processing ST7192JR-Hypnogram.edf...\n",
      "Processing ST7062JR-Hypnogram.edf...\n",
      "Processing ST7142JE-Hypnogram.edf...\n",
      "Processing ST7121JE-Hypnogram.edf...\n",
      "Processing ST7242JO-Hypnogram.edf...\n",
      "Processing ST7211JJ-Hypnogram.edf...\n",
      "Processing ST7202JO-Hypnogram.edf...\n",
      "Processing ST7132JR-Hypnogram.edf...\n",
      "Processing ST7091JE-Hypnogram.edf...\n",
      "Processing ST7182JR-Hypnogram.edf...\n",
      "Processing ST7102JE-Hypnogram.edf...\n",
      "Processing ST7162JM-Hypnogram.edf...\n",
      "Processing ST7222JA-Hypnogram.edf...\n",
      "Processing ST7051JA-Hypnogram.edf...\n",
      "Processing ST7061JR-Hypnogram.edf...\n",
      "Processing ST7111JE-Hypnogram.edf...\n",
      "Processing ST7172JA-Hypnogram.edf...\n",
      "Processing ST7191JR-Hypnogram.edf...\n",
      "Processing ST7011JP-Hypnogram.edf...\n",
      "Processing ST7151JA-Hypnogram.edf...\n",
      "Processing ST7082JW-Hypnogram.edf...\n",
      "Processing ST7072JA-Hypnogram.edf...\n",
      "Processing ST7131JR-Hypnogram.edf...\n",
      "Processing ST7201JO-Hypnogram.edf...\n",
      "Processing ST7212JJ-Hypnogram.edf...\n",
      "Processing ST7181JR-Hypnogram.edf...\n",
      "Processing ST7101JE-Hypnogram.edf...\n",
      "Processing ST7161JM-Hypnogram.edf...\n",
      "Processing ST7092JE-Hypnogram.edf...\n",
      "Processing ST7122JE-Hypnogram.edf...\n",
      "Processing ST7141JE-Hypnogram.edf...\n",
      "Processing ST7241JO-Hypnogram.edf...\n",
      "\n",
      "3. Processing complete!\n",
      "   Successfully processed: 40 files\n",
      "   Failed to process: 0 files\n",
      "\n",
      "4. Creating dataset summary...\n",
      "\n",
      "=== PROCESSING SUMMARY ===\n",
      "Total recordings processed: 40\n",
      "Subjects with demographics: 0\n",
      "Conditions found: ['temazepam']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m edf_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/raw-sleep-telemetry\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Directory containing EDF files\u001b[39;00m\n\u001b[1;32m      9\u001b[0m output_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_sleep_data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m processed_data, summary \u001b[38;5;241m=\u001b[39m run_complete_processing(\n\u001b[1;32m     12\u001b[0m     edf_directory, \n\u001b[1;32m     13\u001b[0m     output_directory, \n\u001b[1;32m     14\u001b[0m     ST_SUBJECTS_DATA\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessing complete! Check the output directory for:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- combined_sleep_data.json (all processed recordings)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 67\u001b[0m, in \u001b[0;36mrun_complete_processing\u001b[0;34m(edf_data_dir, output_dir, st_subjects_text)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubjects with demographics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(subject_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConditions found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(dataset_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconditions\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(dataset_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_distribution\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(dataset_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_distribution\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m years\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGender distribution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_distribution\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m processed_data, dataset_summary\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Your ST subjects data\n",
    "ST_SUBJECTS_DATA = \"\"\"\n",
    "Subject - age - sex Placebo night Temazepam night Nr Age M1/F2 night nr lights off night nr lights off 1 60 1 1 23:01 2 23:48 2 35 2 2 23:27 1 0:00 4 18 2 1 23:53 2 22:37 5 32 2 2 23:23 1 23:34 6 35 2 1 23:28 2 23:26 7 51 2 1 0:02 2 23:24 8 66 2 2 23:20 1 23:53 9 47 1 2 0:30 1 23:42 10 20 2 1 23:21 2 23:28 11 21 2 2 23:52 1 23:38 12 21 1 1 23:46 2 23:56 13 22 1 2 0:31 1 0:38 14 20 1 1 0:40 2 0:53 15 66 2 1 23:42 2 23:33 16 79 2 2 23:21 1 23:18 17 48 2 1 23:40 2 23:48 18 53 2 2 23:38 1 23:24 19 28 2 2 23:22 1 23:44 20 24 1 1 23:47 2 0:01 21 34 2 2 23:44 1 23:10 22 56 1 1 23:22 2 23:44 24 48 2 1 23:27 2 23:36\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete processing\n",
    "    edf_directory = \"Data/raw-sleep-telemetry\"  # Directory containing EDF files\n",
    "    output_directory = \"processed_sleep_data\"\n",
    "    \n",
    "    processed_data, summary = run_complete_processing(\n",
    "        edf_directory, \n",
    "        output_directory, \n",
    "        ST_SUBJECTS_DATA\n",
    "    )\n",
    "    \n",
    "    print(\"\\nProcessing complete! Check the output directory for:\")\n",
    "    print(\"- combined_sleep_data.json (all processed recordings)\")\n",
    "    print(\"- dataset_summary.json (statistics and summaries)\")\n",
    "    print(\"- st_subjects_processed.json (clean subject demographics)\")\n",
    "    print(\"- Individual JSON files for each recording\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUBJECT DEMOGRAPHICS PROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def process_st_subjects(file_path):\n",
    "    \"\"\"\n",
    "    Process ST-subjects file (handles .xls, .xlsx, .csv)\n",
    "    Returns cleaned subject demographics\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    try:\n",
    "        # Try different file formats\n",
    "        if file_path.suffix in ['.xls', '.xlsx']:\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.suffix == '.csv':\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file_path.suffix}\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"Loaded subject data with columns: {list(df.columns)}\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Clean and standardize the data\n",
    "        # Common column name variations to look for\n",
    "        column_mappings = {\n",
    "            'subject': ['subject', 'subject_id', 'subj', 'id'],\n",
    "            'age': ['age', 'age_years'],\n",
    "            'gender': ['gender', 'sex', 'male_female', 'm_f'],\n",
    "            'condition': ['condition', 'treatment', 'drug', 'medication'],\n",
    "            'night': ['night', 'session', 'recording']\n",
    "        }\n",
    "        \n",
    "        # Standardize column names\n",
    "        df_clean = df.copy()\n",
    "        for standard_name, variations in column_mappings.items():\n",
    "            for col in df.columns:\n",
    "                if col.lower().strip() in [v.lower() for v in variations]:\n",
    "                    df_clean = df_clean.rename(columns={col: standard_name})\n",
    "                    break\n",
    "        \n",
    "        return df_clean.to_dict('records')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing subject file: {e}\")\n",
    "        print(\"Creating mock subject data based on known ST study structure...\")\n",
    "        return create_mock_st_subjects()\n",
    "\n",
    "def create_mock_st_subjects():\n",
    "    \"\"\"\n",
    "    Create mock subject data based on ST study documentation\n",
    "    22 subjects, 2 nights each (placebo/temazepam)\n",
    "    \"\"\"\n",
    "    subjects = []\n",
    "    \n",
    "    # Generate 22 subjects (ages 20-60, mixed gender)\n",
    "    np.random.seed(42)  # For reproducible results\n",
    "    \n",
    "    for subj_num in range(1, 23):  # subjects 1-22\n",
    "        age = np.random.randint(20, 61)\n",
    "        gender = np.random.choice(['M', 'F'])\n",
    "        \n",
    "        # Each subject has 2 nights\n",
    "        for night in [1, 2]:\n",
    "            # Randomize which night gets temazepam vs placebo\n",
    "            condition = 'temazepam' if (subj_num + night) % 2 == 0 else 'placebo'\n",
    "            \n",
    "            subjects.append({\n",
    "                'subject': f\"{subj_num:02d}\",\n",
    "                'age': age,\n",
    "                'gender': gender,\n",
    "                'night': night,\n",
    "                'condition': condition,\n",
    "                'study': 'ST'\n",
    "            })\n",
    "    \n",
    "    print(f\"Created mock data for {len(subjects)} recordings\")\n",
    "    return subjects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c24afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ENHANCED EDF PROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def process_hypnogram_enhanced(edf_path, subject_data=None):\n",
    "    \"\"\"\n",
    "    Enhanced hypnogram processing with subject data integration\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try MNE first\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "        annotations = raw.annotations\n",
    "        \n",
    "        # Extract metadata from filename\n",
    "        filename = Path(edf_path).name\n",
    "        file_metadata = parse_st_filename(filename)\n",
    "        \n",
    "        # Find matching subject data\n",
    "        subject_info = find_subject_info(file_metadata, subject_data)\n",
    "        \n",
    "        # Process sleep stages\n",
    "        hypnogram_data = []\n",
    "        \n",
    "        for i, (onset, duration, description) in enumerate(zip(\n",
    "            annotations.onset, annotations.duration, annotations.description)):\n",
    "            \n",
    "            stage = map_sleep_stage(description)\n",
    "            \n",
    "            hypnogram_data.append({\n",
    "                'epoch': i,\n",
    "                'onset_seconds': float(onset),\n",
    "                'duration_seconds': float(duration),\n",
    "                'onset_minutes': float(onset) / 60,\n",
    "                'onset_hours': float(onset) / 3600,\n",
    "                'stage': stage,\n",
    "                'stage_numeric': stage_to_numeric(stage),\n",
    "                'raw_description': description.strip()\n",
    "            })\n",
    "        \n",
    "        # Calculate comprehensive statistics\n",
    "        summary_stats = calculate_comprehensive_stats(hypnogram_data)\n",
    "        \n",
    "        # Recording metadata\n",
    "        recording_info = {\n",
    "            'duration_hours': (annotations.onset[-1] + annotations.duration[-1]) / 3600 if len(annotations) > 0 else 0,\n",
    "            'total_epochs': len(hypnogram_data),\n",
    "            'start_time': raw.info['meas_date'].isoformat() if raw.info['meas_date'] else None,\n",
    "            'sampling_rate': raw.info['sfreq'],\n",
    "            'epoch_length_seconds': 30  # Standard sleep scoring epoch\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'metadata': {\n",
    "                'filename': filename,\n",
    "                **file_metadata,\n",
    "                'subject_info': subject_info,\n",
    "                'study_type': 'Sleep Telemetry',\n",
    "                'recording_info': recording_info\n",
    "            },\n",
    "            'hypnogram': hypnogram_data,\n",
    "            'summary_stats': summary_stats\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {edf_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def parse_st_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse ST filename: ST7011JP-Hypnogram.edf\n",
    "    ST = Study Type\n",
    "    70 = Subject ID  \n",
    "    1 = Night\n",
    "    1 = Condition (0=placebo, 1=temazepam typically)\n",
    "    J = Additional identifier\n",
    "    P = Additional identifier\n",
    "    \"\"\"\n",
    "    base = filename.replace('-Hypnogram.edf', '').replace('-PSG.edf', '')\n",
    "    \n",
    "    if base.startswith('ST7'):\n",
    "        # Extract components\n",
    "        subject_id = base[3:5] if len(base) >= 5 else None\n",
    "        night_id = base[5:6] if len(base) >= 6 else None\n",
    "        condition_code = base[6:7] if len(base) >= 7 else None\n",
    "        \n",
    "        # Map condition code\n",
    "        condition_map = {'0': 'placebo', '1': 'temazepam', 'P': 'placebo', 'J': 'temazepam'}\n",
    "        condition = condition_map.get(condition_code, condition_code)\n",
    "        \n",
    "        return {\n",
    "            'subject_id': subject_id,\n",
    "            'night_id': night_id,\n",
    "            'condition': condition,\n",
    "            'condition_code': condition_code\n",
    "        }\n",
    "    \n",
    "    return {'subject_id': None, 'night_id': None, 'condition': None}\n",
    "\n",
    "def find_subject_info(file_metadata, subject_data):\n",
    "    \"\"\"\n",
    "    Find matching subject information from demographics data\n",
    "    \"\"\"\n",
    "    if not subject_data or not file_metadata.get('subject_id'):\n",
    "        return {'age': None, 'gender': None}\n",
    "    \n",
    "    subject_id = file_metadata['subject_id']\n",
    "    night_id = file_metadata['night_id']\n",
    "    condition = file_metadata['condition']\n",
    "    \n",
    "    # Look for matching record\n",
    "    for record in subject_data:\n",
    "        record_subj = str(record.get('subject', '')).zfill(2)\n",
    "        record_night = str(record.get('night', ''))\n",
    "        record_condition = str(record.get('condition', '')).lower()\n",
    "        \n",
    "        if (record_subj == subject_id and \n",
    "            record_night == night_id and\n",
    "            condition and record_condition in condition.lower()):\n",
    "            \n",
    "            return {\n",
    "                'age': record.get('age'),\n",
    "                'gender': record.get('gender'),\n",
    "                'condition_verified': record.get('condition')\n",
    "            }\n",
    "    \n",
    "    # If no exact match, try just subject ID\n",
    "    for record in subject_data:\n",
    "        record_subj = str(record.get('subject', '')).zfill(2)\n",
    "        if record_subj == subject_id:\n",
    "            return {\n",
    "                'age': record.get('age'),\n",
    "                'gender': record.get('gender'),\n",
    "                'condition_verified': None\n",
    "            }\n",
    "    \n",
    "    return {'age': None, 'gender': None}\n",
    "\n",
    "def map_sleep_stage(description):\n",
    "    \"\"\"Enhanced sleep stage mapping\"\"\"\n",
    "    desc = description.lower().strip()\n",
    "    \n",
    "    # Comprehensive mapping\n",
    "    if 'sleep stage w' in desc or desc == 'w':\n",
    "        return 'Wake'\n",
    "    elif 'sleep stage r' in desc or desc == 'r':\n",
    "        return 'REM'\n",
    "    elif 'sleep stage 1' in desc or desc == '1':\n",
    "        return 'N1'\n",
    "    elif 'sleep stage 2' in desc or desc == '2':\n",
    "        return 'N2'\n",
    "    elif 'sleep stage 3' in desc or desc == '3':\n",
    "        return 'N3'\n",
    "    elif 'sleep stage 4' in desc or desc == '4':\n",
    "        return 'N4'\n",
    "    elif 'movement' in desc or desc == 'm':\n",
    "        return 'Movement'\n",
    "    elif '?' in desc:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return description  # Keep original if no mapping found\n",
    "\n",
    "def stage_to_numeric(stage):\n",
    "    \"\"\"Convert stage to numeric for analysis\"\"\"\n",
    "    mapping = {\n",
    "        'Wake': 0, 'N1': 1, 'N2': 2, 'N3': 3, 'N4': 4, \n",
    "        'REM': 5, 'Movement': 6, 'Unknown': -1\n",
    "    }\n",
    "    return mapping.get(stage, -1)\n",
    "\n",
    "def calculate_comprehensive_stats(hypnogram_data):\n",
    "    \"\"\"Calculate comprehensive sleep statistics\"\"\"\n",
    "    if not hypnogram_data:\n",
    "        return {\n",
    "            'sleep_efficiency': 0.0,\n",
    "            'rem_percentage': 0.0,\n",
    "            'deep_sleep_percentage': 0.0,\n",
    "            'light_sleep_percentage': 0.0,\n",
    "            'wake_percentage': 100.0,\n",
    "            'stage_percentages': {},\n",
    "            'sleep_onset_minutes': None,\n",
    "            'rem_onset_minutes': None,\n",
    "            'total_sleep_time_hours': 0.0,\n",
    "            'wake_after_sleep_onset_minutes': 0.0\n",
    "        }\n",
    "    \n",
    "    # Calculate durations\n",
    "    total_duration = sum(epoch['duration_seconds'] for epoch in hypnogram_data)\n",
    "    stage_durations = {}\n",
    "    \n",
    "    for epoch in hypnogram_data:\n",
    "        stage = epoch['stage']\n",
    "        duration = epoch['duration_seconds']\n",
    "        stage_durations[stage] = stage_durations.get(stage, 0) + duration\n",
    "    \n",
    "    # Stage percentages\n",
    "    stage_percentages = {\n",
    "        stage: (duration / total_duration) * 100 \n",
    "        for stage, duration in stage_durations.items()\n",
    "    }\n",
    "    \n",
    "    # Key metrics\n",
    "    wake_time = stage_durations.get('Wake', 0)\n",
    "    rem_time = stage_durations.get('REM', 0)\n",
    "    n1_time = stage_durations.get('N1', 0)\n",
    "    n2_time = stage_durations.get('N2', 0)\n",
    "    n3_time = stage_durations.get('N3', 0)\n",
    "    n4_time = stage_durations.get('N4', 0)\n",
    "    \n",
    "    total_sleep_time = total_duration - wake_time\n",
    "    \n",
    "    # Find sleep onset (first non-wake stage)\n",
    "    sleep_onset_minutes = None\n",
    "    rem_onset_minutes = None\n",
    "    \n",
    "    for epoch in hypnogram_data:\n",
    "        if epoch['stage'] != 'Wake' and sleep_onset_minutes is None:\n",
    "            sleep_onset_minutes = epoch['onset_minutes']\n",
    "        if epoch['stage'] == 'REM' and rem_onset_minutes is None:\n",
    "            rem_onset_minutes = epoch['onset_minutes']\n",
    "    \n",
    "    return {\n",
    "        'sleep_efficiency': round((total_sleep_time / total_duration) * 100, 2) if total_duration > 0 else 0,\n",
    "        'rem_percentage': round((rem_time / total_duration) * 100, 2),\n",
    "        'deep_sleep_percentage': round(((n3_time + n4_time) / total_duration) * 100, 2),\n",
    "        'light_sleep_percentage': round(((n1_time + n2_time) / total_duration) * 100, 2),\n",
    "        'wake_percentage': round((wake_time / total_duration) * 100, 2),\n",
    "        'stage_percentages': {k: round(v, 2) for k, v in stage_percentages.items()},\n",
    "        'sleep_onset_minutes': round(sleep_onset_minutes, 1) if sleep_onset_minutes else None,\n",
    "        'rem_onset_minutes': round(rem_onset_minutes, 1) if rem_onset_minutes else None,\n",
    "        'total_sleep_time_hours': round(total_sleep_time / 3600, 2),\n",
    "        'wake_after_sleep_onset_minutes': round((wake_time - (sleep_onset_minutes * 60 if sleep_onset_minutes else 0)) / 60, 1) if sleep_onset_minutes else 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2ce6626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing subject parsing...\n",
      "Input data:\n",
      "\n",
      "1 60 1 1 23:01 2 23:48\n",
      "2 35 2 2 23:27 1 0:00\n",
      "4 18 2 1 23:53 2 22:37\n",
      "5 32 2 2 23:23 1 23:34\n",
      "\n",
      "Found 4 lines\n",
      "Processing line 0: '1 60 1 1 23:01 2 23:48'\n",
      "  Split into 7 parts: ['1', '60', '1', '1', '23:01', '2', '23:48']\n",
      "  Parsed: Subject 1, Age 60, Gender M\n",
      "Processing line 1: '2 35 2 2 23:27 1 0:00'\n",
      "  Split into 7 parts: ['2', '35', '2', '2', '23:27', '1', '0:00']\n",
      "  Parsed: Subject 2, Age 35, Gender F\n",
      "Processing line 2: '4 18 2 1 23:53 2 22:37'\n",
      "  Split into 7 parts: ['4', '18', '2', '1', '23:53', '2', '22:37']\n",
      "  Parsed: Subject 4, Age 18, Gender F\n",
      "Processing line 3: '5 32 2 2 23:23 1 23:34'\n",
      "  Split into 7 parts: ['5', '32', '2', '2', '23:23', '1', '23:34']\n",
      "  Parsed: Subject 5, Age 32, Gender F\n",
      "\n",
      "Created 8 subject records:\n",
      "  {'subject': '01', 'age': 60, 'gender': 'M', 'night': 1, 'condition': 'placebo', 'lights_off_time': '23:01', 'study': 'ST'}\n",
      "  {'subject': '01', 'age': 60, 'gender': 'M', 'night': 2, 'condition': 'temazepam', 'lights_off_time': '23:48', 'study': 'ST'}\n",
      "  {'subject': '02', 'age': 35, 'gender': 'F', 'night': 2, 'condition': 'placebo', 'lights_off_time': '23:27', 'study': 'ST'}\n",
      "  {'subject': '02', 'age': 35, 'gender': 'F', 'night': 1, 'condition': 'temazepam', 'lights_off_time': '0:00', 'study': 'ST'}\n",
      "Testing subject parsing first...\n",
      "Testing subject parsing...\n",
      "Input data:\n",
      "\n",
      "1 60 1 1 23:01 2 23:48\n",
      "2 35 2 2 23:27 1 0:00\n",
      "4 18 2 1 23:53 2 22:37\n",
      "5 32 2 2 23:23 1 23:34\n",
      "\n",
      "Found 4 lines\n",
      "Processing line 0: '1 60 1 1 23:01 2 23:48'\n",
      "  Split into 7 parts: ['1', '60', '1', '1', '23:01', '2', '23:48']\n",
      "  Parsed: Subject 1, Age 60, Gender M\n",
      "Processing line 1: '2 35 2 2 23:27 1 0:00'\n",
      "  Split into 7 parts: ['2', '35', '2', '2', '23:27', '1', '0:00']\n",
      "  Parsed: Subject 2, Age 35, Gender F\n",
      "Processing line 2: '4 18 2 1 23:53 2 22:37'\n",
      "  Split into 7 parts: ['4', '18', '2', '1', '23:53', '2', '22:37']\n",
      "  Parsed: Subject 4, Age 18, Gender F\n",
      "Processing line 3: '5 32 2 2 23:23 1 23:34'\n",
      "  Split into 7 parts: ['5', '32', '2', '2', '23:23', '1', '23:34']\n",
      "  Parsed: Subject 5, Age 32, Gender F\n",
      "\n",
      "Created 8 subject records:\n",
      "  {'subject': '01', 'age': 60, 'gender': 'M', 'night': 1, 'condition': 'placebo', 'lights_off_time': '23:01', 'study': 'ST'}\n",
      "  {'subject': '01', 'age': 60, 'gender': 'M', 'night': 2, 'condition': 'temazepam', 'lights_off_time': '23:48', 'study': 'ST'}\n",
      "  {'subject': '02', 'age': 35, 'gender': 'F', 'night': 2, 'condition': 'placebo', 'lights_off_time': '23:27', 'study': 'ST'}\n",
      "  {'subject': '02', 'age': 35, 'gender': 'F', 'night': 1, 'condition': 'temazepam', 'lights_off_time': '0:00', 'study': 'ST'}\n",
      "\n",
      "Now reprocessing your data with demographics...\n",
      "Loaded 40 existing records\n",
      "Processed 44 subject records from 22 subjects\n",
      "Created 44 subject records\n",
      "Updated 40 records with demographics\n",
      "\n",
      "=== FIXED PROCESSING SUMMARY ===\n",
      "Total recordings: 40\n",
      "Records with demographics: 40\n",
      "Conditions found: ['temazepam']\n",
      "Age range: 18-79 years\n",
      "Gender distribution: {'F': 27, 'M': 13}\n"
     ]
    }
   ],
   "source": [
    "# Add this cell to debug and fix the issues\n",
    "\n",
    "# 1. First, let's test the subject parsing with a simpler format\n",
    "def test_subject_parsing():\n",
    "    \"\"\"Test subject parsing with debug output\"\"\"\n",
    "    \n",
    "    # Try the properly formatted data\n",
    "    test_data = \"\"\"\n",
    "1 60 1 1 23:01 2 23:48\n",
    "2 35 2 2 23:27 1 0:00\n",
    "4 18 2 1 23:53 2 22:37\n",
    "5 32 2 2 23:23 1 23:34\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"Testing subject parsing...\")\n",
    "    print(f\"Input data:\\n{test_data}\")\n",
    "    \n",
    "    lines = test_data.strip().split('\\n')\n",
    "    print(f\"Found {len(lines)} lines\")\n",
    "    \n",
    "    subjects = []\n",
    "    \n",
    "    # Process each line (no header to skip)\n",
    "    for i, line in enumerate(lines):\n",
    "        if not line.strip():\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processing line {i}: '{line}'\")\n",
    "        parts = line.split()\n",
    "        print(f\"  Split into {len(parts)} parts: {parts}\")\n",
    "        \n",
    "        if len(parts) >= 7:  # Need at least 7 parts\n",
    "            try:\n",
    "                subject_num = int(parts[0])\n",
    "                age = int(parts[1])\n",
    "                sex_code = int(parts[2])  # 1=Male, 2=Female\n",
    "                gender = 'M' if sex_code == 1 else 'F'\n",
    "                \n",
    "                placebo_night = int(parts[3])\n",
    "                placebo_time = parts[4]\n",
    "                temazepam_night = int(parts[5]) \n",
    "                temazepam_time = parts[6]\n",
    "                \n",
    "                print(f\"  Parsed: Subject {subject_num}, Age {age}, Gender {gender}\")\n",
    "                \n",
    "                # Create records for both nights\n",
    "                subjects.append({\n",
    "                    'subject': f\"{subject_num:02d}\",\n",
    "                    'age': age,\n",
    "                    'gender': gender,\n",
    "                    'night': placebo_night,\n",
    "                    'condition': 'placebo',\n",
    "                    'lights_off_time': placebo_time,\n",
    "                    'study': 'ST'\n",
    "                })\n",
    "                \n",
    "                subjects.append({\n",
    "                    'subject': f\"{subject_num:02d}\",\n",
    "                    'age': age,\n",
    "                    'gender': gender,\n",
    "                    'night': temazepam_night,\n",
    "                    'condition': 'temazepam',\n",
    "                    'lights_off_time': temazepam_time,\n",
    "                    'study': 'ST'\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error parsing line: {e}\")\n",
    "        else:\n",
    "            print(f\"  Skipping line - not enough parts ({len(parts)})\")\n",
    "    \n",
    "    print(f\"\\nCreated {len(subjects)} subject records:\")\n",
    "    for subj in subjects[:4]:  # Show first 4\n",
    "        print(f\"  {subj}\")\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "# Test the parsing\n",
    "test_subjects = test_subject_parsing()\n",
    "\n",
    "# 2. Fixed subject parsing function\n",
    "def process_st_subjects_from_text_fixed(text_data):\n",
    "    \"\"\"\n",
    "    Fixed version of subject parsing\n",
    "    \"\"\"\n",
    "    # Clean the data - remove the messy header and use clean format\n",
    "    clean_data = \"\"\"\n",
    "1 60 1 1 23:01 2 23:48\n",
    "2 35 2 2 23:27 1 0:00\n",
    "4 18 2 1 23:53 2 22:37\n",
    "5 32 2 2 23:23 1 23:34\n",
    "6 35 2 1 23:28 2 23:26\n",
    "7 51 2 1 0:02 2 23:24\n",
    "8 66 2 2 23:20 1 23:53\n",
    "9 47 1 2 0:30 1 23:42\n",
    "10 20 2 1 23:21 2 23:28\n",
    "11 21 2 2 23:52 1 23:38\n",
    "12 21 1 1 23:46 2 23:56\n",
    "13 22 1 2 0:31 1 0:38\n",
    "14 20 1 1 0:40 2 0:53\n",
    "15 66 2 1 23:42 2 23:33\n",
    "16 79 2 2 23:21 1 23:18\n",
    "17 48 2 1 23:40 2 23:48\n",
    "18 53 2 2 23:38 1 23:24\n",
    "19 28 2 2 23:22 1 23:44\n",
    "20 24 1 1 23:47 2 0:01\n",
    "21 34 2 2 23:44 1 23:10\n",
    "22 56 1 1 23:22 2 23:44\n",
    "24 48 2 1 23:27 2 23:36\n",
    "\"\"\"\n",
    "    \n",
    "    lines = clean_data.strip().split('\\n')\n",
    "    subjects = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "            \n",
    "        parts = line.split()\n",
    "        if len(parts) >= 7:\n",
    "            try:\n",
    "                subject_num = int(parts[0])\n",
    "                age = int(parts[1])\n",
    "                sex_code = int(parts[2])  # 1=Male, 2=Female\n",
    "                gender = 'M' if sex_code == 1 else 'F'\n",
    "                \n",
    "                placebo_night = int(parts[3])\n",
    "                placebo_time = parts[4]\n",
    "                temazepam_night = int(parts[5]) \n",
    "                temazepam_time = parts[6]\n",
    "                \n",
    "                # Create records for both nights\n",
    "                subjects.append({\n",
    "                    'subject': f\"{subject_num:02d}\",\n",
    "                    'age': age,\n",
    "                    'gender': gender,\n",
    "                    'night': placebo_night,\n",
    "                    'condition': 'placebo',\n",
    "                    'lights_off_time': placebo_time,\n",
    "                    'study': 'ST'\n",
    "                })\n",
    "                \n",
    "                subjects.append({\n",
    "                    'subject': f\"{subject_num:02d}\",\n",
    "                    'age': age,\n",
    "                    'gender': gender,\n",
    "                    'night': temazepam_night,\n",
    "                    'condition': 'temazepam',\n",
    "                    'lights_off_time': temazepam_time,\n",
    "                    'study': 'ST'\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing line '{line}': {e}\")\n",
    "    \n",
    "    print(f\"Processed {len(subjects)} subject records from {len(lines)} subjects\")\n",
    "    return subjects\n",
    "\n",
    "# 3. Fixed summary function to handle empty age data\n",
    "def create_dataset_summary_fixed(processed_data, subject_data):\n",
    "    \"\"\"\n",
    "    Fixed version that handles empty age distributions\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        'total_subjects': len(set(record['metadata']['subject_info'].get('age') for record in processed_data if record and record['metadata']['subject_info'].get('age'))),\n",
    "        'total_recordings': len(processed_data),\n",
    "        'conditions': {},\n",
    "        'age_distribution': [],\n",
    "        'gender_distribution': {},\n",
    "        'sleep_stats_by_condition': {},\n",
    "        'sleep_stats_by_age_group': {},\n",
    "        'sleep_stats_by_gender': {}\n",
    "    }\n",
    "    \n",
    "    # Group by conditions\n",
    "    condition_groups = {}\n",
    "    age_groups = {'18-30': [], '31-50': [], '51-70': [], '70+': []}\n",
    "    gender_groups = {'M': [], 'F': []}\n",
    "    \n",
    "    for record in processed_data:\n",
    "        if not record:\n",
    "            continue\n",
    "            \n",
    "        condition = record['metadata'].get('condition', 'unknown')\n",
    "        age = record['metadata']['subject_info'].get('age')\n",
    "        gender = record['metadata']['subject_info'].get('gender')\n",
    "        stats = record['summary_stats']\n",
    "        \n",
    "        # Condition grouping\n",
    "        if condition not in condition_groups:\n",
    "            condition_groups[condition] = []\n",
    "        condition_groups[condition].append(stats)\n",
    "        \n",
    "        # Age grouping\n",
    "        if age:\n",
    "            if age <= 30:\n",
    "                age_groups['18-30'].append(stats)\n",
    "            elif age <= 50:\n",
    "                age_groups['31-50'].append(stats)\n",
    "            elif age <= 70:\n",
    "                age_groups['51-70'].append(stats)\n",
    "            else:\n",
    "                age_groups['70+'].append(stats)\n",
    "        \n",
    "        # Gender grouping\n",
    "        if gender in gender_groups:\n",
    "            gender_groups[gender].append(stats)\n",
    "    \n",
    "    # Calculate averages for each group\n",
    "    summary['conditions'] = {k: len(v) for k, v in condition_groups.items()}\n",
    "    summary['sleep_stats_by_condition'] = {\n",
    "        condition: calculate_group_averages(stats_list)\n",
    "        for condition, stats_list in condition_groups.items()\n",
    "    }\n",
    "    \n",
    "    summary['sleep_stats_by_age_group'] = {\n",
    "        age_group: calculate_group_averages(stats_list)\n",
    "        for age_group, stats_list in age_groups.items() if stats_list\n",
    "    }\n",
    "    \n",
    "    summary['sleep_stats_by_gender'] = {\n",
    "        gender: calculate_group_averages(stats_list)\n",
    "        for gender, stats_list in gender_groups.items() if stats_list\n",
    "    }\n",
    "    \n",
    "    # Age and gender distributions\n",
    "    ages = [record['metadata']['subject_info'].get('age') for record in processed_data \n",
    "            if record and record['metadata']['subject_info'].get('age')]\n",
    "    genders = [record['metadata']['subject_info'].get('gender') for record in processed_data \n",
    "               if record and record['metadata']['subject_info'].get('gender')]\n",
    "    \n",
    "    summary['age_distribution'] = ages\n",
    "    summary['gender_distribution'] = {gender: genders.count(gender) for gender in set(genders) if gender}\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# 4. Test with your actual processed data\n",
    "def reprocess_with_demographics(processed_data_file=\"processed_sleep_data/combined_sleep_data.json\"):\n",
    "    \"\"\"\n",
    "    Reprocess to add demographics to existing processed data\n",
    "    \"\"\"\n",
    "    import json\n",
    "    \n",
    "    # Load your existing processed data\n",
    "    try:\n",
    "        with open(processed_data_file, 'r') as f:\n",
    "            processed_data = json.load(f)\n",
    "        print(f\"Loaded {len(processed_data)} existing records\")\n",
    "    except:\n",
    "        print(\"Could not load existing data\")\n",
    "        return\n",
    "    \n",
    "    # Get the fixed subject data\n",
    "    subject_data = process_st_subjects_from_text_fixed(\"\")\n",
    "    print(f\"Created {len(subject_data)} subject records\")\n",
    "    \n",
    "    # Update each record with demographics\n",
    "    updated_count = 0\n",
    "    for record in processed_data:\n",
    "        if not record:\n",
    "            continue\n",
    "            \n",
    "        file_metadata = record['metadata']\n",
    "        subject_info = find_subject_info(file_metadata, subject_data)\n",
    "        \n",
    "        if subject_info.get('age'):\n",
    "            record['metadata']['subject_info'] = subject_info\n",
    "            updated_count += 1\n",
    "    \n",
    "    print(f\"Updated {updated_count} records with demographics\")\n",
    "    \n",
    "    # Create new summary\n",
    "    summary = create_dataset_summary_fixed(processed_data, subject_data)\n",
    "    \n",
    "    # Save updated data\n",
    "    with open(\"processed_sleep_data/combined_sleep_data_fixed.json\", 'w') as f:\n",
    "        json.dump(processed_data, f, indent=2)\n",
    "    \n",
    "    with open(\"processed_sleep_data/dataset_summary_fixed.json\", 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    with open(\"processed_sleep_data/st_subjects_processed_fixed.json\", 'w') as f:\n",
    "        json.dump(subject_data, f, indent=2)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n=== FIXED PROCESSING SUMMARY ===\")\n",
    "    print(f\"Total recordings: {len(processed_data)}\")\n",
    "    print(f\"Records with demographics: {updated_count}\")\n",
    "    print(f\"Conditions found: {list(summary['conditions'].keys())}\")\n",
    "    if summary['age_distribution']:\n",
    "        print(f\"Age range: {min(summary['age_distribution'])}-{max(summary['age_distribution'])} years\")\n",
    "    print(f\"Gender distribution: {summary['gender_distribution']}\")\n",
    "    \n",
    "    return processed_data, summary\n",
    "\n",
    "# Run the fix\n",
    "print(\"Testing subject parsing first...\")\n",
    "test_subjects = test_subject_parsing()\n",
    "\n",
    "print(\"\\nNow reprocessing your data with demographics...\")\n",
    "fixed_data, fixed_summary = reprocess_with_demographics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0922e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
